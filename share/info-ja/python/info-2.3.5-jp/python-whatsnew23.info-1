This is python-whatsnew23.info, produced by makeinfo version 4.5 from
python-whatsnew23.texi.


File: python-whatsnew23.info,  Node: Top,  Next: PEP 218 A Standard Set Datatype,  Prev: (dir),  Up: (dir)

What's New in Python 2.3
************************

This article explains the new features in Python 2.3.  Python 2.3 was
released on July 29, 2003.

The main themes for Python 2.3 are polishing some of the features added
in 2.2, adding various small but useful enhancements to the core
language, and expanding the standard library.  The new object model
introduced in the previous version has benefited from 18 months of
bugfixes and from optimization efforts that have improved the
performance of new-style classes.  A few new built-in functions have
been added such as `sum()' and `enumerate()'.  The `in' operator can
now be used for substring searches (e.g.  `"ab" in "abc"' returns
`True').

Some of the many new library features include Boolean, set, heap, and
date/time data types, the ability to import modules from ZIP-format
archives, metadata support for the long-awaited Python catalog, an
updated version of IDLE, and modules for logging messages, wrapping
text, parsing CSV files, processing command-line options, using
BerkeleyDB databases...  the list of new and enhanced modules is
lengthy.

This article doesn't attempt to provide a complete specification of the
new features, but instead provides a convenient overview.  For full
details, you should refer to the documentation for Python 2.3, such as
the  and the .  If you want to understand the complete implementation
and design rationale, refer to the PEP for a particular new feature.

* Menu:

* PEP 218 A Standard Set Datatype::
* PEP 255 Simple Generators::
* PEP 263 Source Code Encodings::
* PEP 273 Importing Modules from Zip Archives::
* PEP 277 Unicode file name support for Windows NT::
* PEP 278 Universal Newline Support::
* PEP 279 enumerate::
* PEP 282 logging Package::
* PEP 285 A Boolean Type::
* PEP 293 Codec Error Handling Callbacks::
* PEP 301 Package Index and Metadata for Distutils::
* PEP 302 New Import Hooks::
* PEP 305 Comma-separated Files::
* PEP 307 Pickle Enhancements::
* Extended Slices::
* Other Language Changes::
* New::
* Pymalloc A Specialized Object Allocator::
* Build and C API Changes::
* Other Changes and Fixes::
* Porting to Python 23::
* Acknowledgements::
* Miscellaneous Index::


File: python-whatsnew23.info,  Node: PEP 218 A Standard Set Datatype,  Next: PEP 255 Simple Generators,  Prev: Top,  Up: Top

PEP 218: A Standard Set Datatype
********************************

The new `sets' module contains an implementation of a set datatype.
The `Set' class is for mutable sets, sets that can have members added
and removed.  The `ImmutableSet' class is for sets that can't be
modified, and instances of `ImmutableSet' can therefore be used as
dictionary keys.  Sets are built on top of dictionaries, so the
elements within a set must be hashable.

Here's a simple example:

     >>> import sets
     >>> S = sets.Set([1,2,3])
     >>> S
     Set([1, 2, 3])
     >>> 1 in S
     True
     >>> 0 in S
     False
     >>> S.add(5)
     >>> S.remove(3)
     >>> S
     Set([1, 2, 5])
     >>>

The union and intersection of sets can be computed with the `union()'
and `intersection()' methods; an alternative notation uses the bitwise
operators `&' and `|'.  Mutable sets also have in-place versions of
these methods, `union_update()' and `intersection_update()'.

     >>> S1 = sets.Set([1,2,3])
     >>> S2 = sets.Set([4,5,6])
     >>> S1.union(S2)
     Set([1, 2, 3, 4, 5, 6])
     >>> S1 | S2                  # Alternative notation
     Set([1, 2, 3, 4, 5, 6])
     >>> S1.intersection(S2)
     Set([])
     >>> S1 & S2                  # Alternative notation
     Set([])
     >>> S1.union_update(S2)
     >>> S1
     Set([1, 2, 3, 4, 5, 6])
     >>>

It's also possible to take the symmetric difference of two sets.  This
is the set of all elements in the union that aren't in the
intersection.  Another way of putting it is that the symmetric
difference contains all elements that are in exactly one set.  Again,
there's an alternative notation (`^'), and an in-place version with the
ungainly name `symmetric_difference_update()'.

     >>> S1 = sets.Set([1,2,3,4])
     >>> S2 = sets.Set([3,4,5,6])
     >>> S1.symmetric_difference(S2)
     Set([1, 2, 5, 6])
     >>> S1 ^ S2
     Set([1, 2, 5, 6])
     >>>

There are also `issubset()' and `issuperset()' methods for checking
whether one set is a subset or superset of another:

     >>> S1 = sets.Set([1,2,3])
     >>> S2 = sets.Set([2,3])
     >>> S2.issubset(S1)
     True
     >>> S1.issubset(S2)
     False
     >>> S1.issuperset(S2)
     True
     >>>

See also:
    *PEP218 Adding a Built-In Set Object Type*
          PEP written by Greg V. Wilson. Implemented by Greg V. Wilson,
          Alex Martelli, and GvR.



File: python-whatsnew23.info,  Node: PEP 255 Simple Generators,  Next: PEP 263 Source Code Encodings,  Prev: PEP 218 A Standard Set Datatype,  Up: Top

PEP 255: Simple Generators
**************************

In Python 2.2, generators were added as an optional feature, to be
enabled by a `from __future__ import generators' directive.  In 2.3
generators no longer need to be specially enabled, and are now always
present; this means that `yield' is now always a keyword.  The rest of
this section is a copy of the description of generators from the
"What's New in Python 2.2" document; if you read it back when Python
2.2 came out, you can skip the rest of this section.

You're doubtless familiar with how function calls work in Python or C.
When you call a function, it gets a private namespace where its local
variables are created.  When the function reaches a `return' statement,
the local variables are destroyed and the resulting value is returned
to the caller.  A later call to the same function will get a fresh new
set of local variables. But, what if the local variables weren't thrown
away on exiting a function?  What if you could later resume the
function where it left off?  This is what generators provide; they can
be thought of as resumable functions.

Here's the simplest example of a generator function:

     def generate_ints(N):
         for i in range(N):
             yield i

A new keyword, `yield', was introduced for generators.  Any function
containing a `yield' statement is a generator function; this is
detected by Python's bytecode compiler which compiles the function
specially as a result.

When you call a generator function, it doesn't return a single value;
instead it returns a generator object that supports the iterator
protocol.  On executing the `yield' statement, the generator outputs
the value of `i', similar to a `return' statement.  The big difference
between `yield' and a `return' statement is that on reaching a `yield'
the generator's state of execution is suspended and local variables are
preserved.  On the next call to the generator's `.next()' method, the
function will resume executing immediately after the `yield' statement.
(For complicated reasons, the `yield' statement isn't allowed inside
the `try' block of a `try'...`finally' statement; read PEP 255 for a
full explanation of the interaction between `yield' and exceptions.)

Here's a sample usage of the `generate_ints()' generator:

     >>> gen = generate_ints(3)
     >>> gen
     <generator object at 0x8117f90>
     >>> gen.next()
     0
     >>> gen.next()
     1
     >>> gen.next()
     2
     >>> gen.next()
     Traceback (most recent call last):
       File "stdin", line 1, in ?
       File "stdin", line 2, in generate_ints
     StopIteration

You could equally write `for i in generate_ints(5)', or `a,b,c =
generate_ints(3)'.

Inside a generator function, the `return' statement can only be used
without a value, and signals the end of the procession of values;
afterwards the generator cannot return any further values.  `return'
with a value, such as `return 5', is a syntax error inside a generator
function.  The end of the generator's results can also be indicated by
raising `StopIteration' manually, or by just letting the flow of
execution fall off the bottom of the function.

You could achieve the effect of generators manually by writing your own
class and storing all the local variables of the generator as instance
variables.  For example, returning a list of integers could be done by
setting `self.count' to 0, and having the `next()' method increment
`self.count' and return it.  However, for a moderately complicated
generator, writing a corresponding class would be much messier.
`Lib/test/test_generators.py' contains a number of more interesting
examples.  The simplest one implements an in-order traversal of a tree
using generators recursively.

     # A recursive generator that generates Tree leaves in in-order.
     def inorder(t):
         if t:
             for x in inorder(t.left):
                 yield x
             yield t.label
             for x in inorder(t.right):
                 yield x

Two other examples in `Lib/test/test_generators.py' produce solutions
for the N-Queens problem (placing $N$ queens on an $NxN$ chess board so
that no queen threatens another) and the Knight's Tour (a route that
takes a knight to every square of an $NxN$ chessboard without visiting
any square twice).

The idea of generators comes from other programming languages,
especially Icon (<http://www.cs.arizona.edu/icon/>), where the idea of
generators is central.  In Icon, every expression and function call
behaves like a generator.  One example from "An Overview of the Icon
Programming Language" at
<http://www.cs.arizona.edu/icon/docs/ipd266.htm> gives an idea of what
this looks like:

     sentence := "Store it in the neighboring harbor"
     if (i := find("or", sentence)) > 5 then write(i)

In Icon the `find()' function returns the indexes at which the
substring "or" is found: 3, 23, 33.  In the `if' statement, `i' is
first assigned a value of 3, but 3 is less than 5, so the comparison
fails, and Icon retries it with the second value of 23.  23 is greater
than 5, so the comparison now succeeds, and the code prints the value
23 to the screen.

Python doesn't go nearly as far as Icon in adopting generators as a
central concept.  Generators are considered part of the core Python
language, but learning or using them isn't compulsory; if they don't
solve any problems that you have, feel free to ignore them.  One novel
feature of Python's interface as compared to Icon's is that a
generator's state is represented as a concrete object (the iterator)
that can be passed around to other functions or stored in a data
structure.

See also:
    *PEP255 Simple Generators*
          Written by Neil Schemenauer, Tim Peters, Magnus Lie Hetland.
          Implemented mostly by Neil Schemenauer and Tim Peters, with
          other fixes from the Python Labs crew.



File: python-whatsnew23.info,  Node: PEP 263 Source Code Encodings,  Next: PEP 273 Importing Modules from Zip Archives,  Prev: PEP 255 Simple Generators,  Up: Top

PEP 263: Source Code Encodings
******************************

Python source files can now be declared as being in different character
set encodings.  Encodings are declared by including a specially
formatted comment in the first or second line of the source file.  For
example, a UTF-8 file can be declared with:

     #!/usr/bin/env python
     # -*- coding: UTF-8 -*-

Without such an encoding declaration, the default encoding used is
7-bit ASCII.  Executing or importing modules that contain string
literals with 8-bit characters and have no encoding declaration will
result in a `DeprecationWarning' being signalled by Python 2.3; in 2.4
this will be a syntax error.

The encoding declaration only affects Unicode string literals, which
will be converted to Unicode using the specified encoding.  Note that
Python identifiers are still restricted to ASCII characters, so you
can't have variable names that use characters outside of the usual
alphanumerics.

See also:
    *PEP263 Defining Python Source Code Encodings*
          Written by Marc-Andr'e Lemburg and Martin von~L"owis;
          implemented by Suzuki Hisao and Martin von~L"owis.



File: python-whatsnew23.info,  Node: PEP 273 Importing Modules from Zip Archives,  Next: PEP 277 Unicode file name support for Windows NT,  Prev: PEP 263 Source Code Encodings,  Up: Top

PEP 273: Importing Modules from Zip Archives
********************************************

The new `zipimport' module adds support for importing modules from a
ZIP-format archive.  You don't need to import the module explicitly; it
will be automatically imported if a ZIP archive's filename is added to
`sys.path'.  For example:

     amk@nyman:~/src/python$ unzip -l /tmp/example.zip
     Archive:  /tmp/example.zip
       Length     Date   Time    Name
      --------    ----   ----    ----
          8467  11-26-02 22:30   jwzthreading.py
      --------                   -------
          8467                   1 file
     amk@nyman:~/src/python$ ./python
     Python 2.3 (#1, Aug 1 2003, 19:54:32)
     >>> import sys
     >>> sys.path.insert(0, '/tmp/example.zip')  # Add .zip file to front of path
     >>> import jwzthreading
     >>> jwzthreading.__file__
     '/tmp/example.zip/jwzthreading.py'
     >>>

An entry in `sys.path' can now be the filename of a ZIP archive.  The
ZIP archive can contain any kind of files, but only files named `*.py',
`*.pyc', or `*.pyo' can be imported.  If an archive only contains
`*.py' files, Python will not attempt to modify the archive by adding
the corresponding `*.pyc' file, meaning that if a ZIP archive doesn't
contain `*.pyc' files, importing may be rather slow.

A path within the archive can also be specified to only import from a
subdirectory; for example, the path `/tmp/example.zip/lib/' would only
import from the `lib/' subdirectory within the archive.

See also:
    *PEP273 Import Modules from Zip Archives*
          Written by James C. Ahlstrom,  who also provided an
          implementation. Python 2.3 follows the specification in PEP
          273 ,  but uses an implementation written by Just van~Rossum
          that uses the import hooks described in PEP 302 . See
          section~*Note PEP 302 New Import Hooks:: for a description of
          the new import hooks.



File: python-whatsnew23.info,  Node: PEP 277 Unicode file name support for Windows NT,  Next: PEP 278 Universal Newline Support,  Prev: PEP 273 Importing Modules from Zip Archives,  Up: Top

PEP 277: Unicode file name support for Windows NT
*************************************************

On Windows NT, 2000, and XP, the system stores file names as Unicode
strings. Traditionally, Python has represented file names as byte
strings, which is inadequate because it renders some file names
inaccessible.

Python now allows using arbitrary Unicode strings (within the
limitations of the file system) for all functions that expect file
names, most notably the `open()' built-in function. If a Unicode string
is passed to `os.listdir()', Python now returns a list of Unicode
strings.  A new function, `os.getcwdu()', returns the current directory
as a Unicode string.

Byte strings still work as file names, and on Windows Python will
transparently convert them to Unicode using the `mbcs' encoding.

Other systems also allow Unicode strings as file names but convert them
to byte strings before passing them to the system, which can cause a
`UnicodeError' to be raised. Applications can test whether arbitrary
Unicode strings are supported as file names by checking
`os.path.supports_unicode_filenames', a Boolean value.

Under MacOS, `os.listdir()' may now return Unicode filenames.

See also:
    *PEP277 Unicode file name support for Windows NT*
          Written by Neil Hodgson; implemented by Neil Hodgson, Martin
          von~L"owis, and Mark Hammond.



File: python-whatsnew23.info,  Node: PEP 278 Universal Newline Support,  Next: PEP 279 enumerate,  Prev: PEP 277 Unicode file name support for Windows NT,  Up: Top

PEP 278: Universal Newline Support
**********************************

The three major operating systems used today are Microsoft Windows,
Apple's Macintosh OS, and the various UNIX derivatives.  A minor
irritation of cross-platform work is that these three platforms all use
different characters to mark the ends of lines in text files.  UNIX
uses the linefeed (ASCII character 10), MacOS uses the carriage return
(ASCII character 13), and Windows uses a two-character sequence of a
carriage return plus a newline.

Python's file objects can now support end of line conventions other
than the one followed by the platform on which Python is running.
Opening a file with the mode `'U'' or `'rU'' will open a file for
reading in universal newline mode.  All three line ending conventions
will be translated to a `\n' in the strings returned by the various
file methods such as `read()' and `readline()'.

Universal newline support is also used when importing modules and when
executing a file with the `execfile()' function.  This means that
Python modules can be shared between all three operating systems
without needing to convert the line-endings.

This feature can be disabled when compiling Python by specifying the
`--without-universal-newlines' switch when running Python's `configure'
script.

See also:
    *PEP278 Universal Newline Support*
          Written and implemented by Jack Jansen.



File: python-whatsnew23.info,  Node: PEP 279 enumerate,  Next: PEP 282 logging Package,  Prev: PEP 278 Universal Newline Support,  Up: Top

PEP 279: enumerate()
********************

A new built-in function, `enumerate()', will make certain loops a bit
clearer.  `enumerate(thing)', where THING is either an iterator or a
sequence, returns a iterator that will return `(0, THING[0])', `(1,
THING[1])', `(2, THING[2])', and so forth.

A common idiom to change every element of a list looks like this:

     for i in range(len(L)):
         item = L[i]
         # ... compute some result based on item ...
         L[i] = result

This can be rewritten using `enumerate()' as:

     for i, item in enumerate(L):
         # ... compute some result based on item ...
         L[i] = result

See also:
    *PEP279 The enumerate() built-in function*
          Written and implemented by Raymond D. Hettinger.



File: python-whatsnew23.info,  Node: PEP 282 logging Package,  Next: PEP 285 A Boolean Type,  Prev: PEP 279 enumerate,  Up: Top

PEP 282: The logging Package
****************************

A standard package for writing logs, `logging', has been added to
Python 2.3.  It provides a powerful and flexible mechanism for
generating logging output which can then be filtered and processed in
various ways.  A configuration file written in a standard format can be
used to control the logging behavior of a program.  Python includes
handlers that will write log records to standard error or to a file or
socket, send them to the system log, or even e-mail them to a
particular address; of course, it's also possible to write your own
handler classes.

The `Logger' class is the primary class.  Most application code will
deal with one or more `Logger' objects, each one used by a particular
subsystem of the application.  Each `Logger' is identified by a name,
and names are organized into a hierarchy using `.'  as the component
separator.  For example, you might have `Logger' instances named
`server', `server.auth' and `server.network'.  The latter two instances
are below `server' in the hierarchy.  This means that if you turn up
the verbosity for `server' or direct `server' messages to a different
handler, the changes will also apply to records logged to `server.auth'
and `server.network'.  There's also a root `Logger' that's the parent
of all other loggers.

For simple uses, the `logging' package contains some convenience
functions that always use the root log:

     import logging
     
     logging.debug('Debugging information')
     logging.info('Informational message')
     logging.warning('Warning:config file %s not found', 'server.conf')
     logging.error('Error occurred')
     logging.critical('Critical error -- shutting down')

This produces the following output:

     WARNING:root:Warning:config file server.conf not found
     ERROR:root:Error occurred
     CRITICAL:root:Critical error -- shutting down

In the default configuration, informational and debugging messages are
suppressed and the output is sent to standard error.  You can enable
the display of informational and debugging messages by calling the
`setLevel()' method on the root logger.

Notice the `warning()' call's use of string formatting operators; all
of the functions for logging messages take the arguments `(MSG, ARG1,
ARG2, ...)' and log the string resulting from `MSG % (ARG1, ARG2, ...)'.

There's also an `exception()' function that records the most recent
traceback.  Any of the other functions will also record the traceback
if you specify a true value for the keyword argument EXC_INFO.

     def f():
         try:    1/0
         except: logging.exception('Problem recorded')
     
     f()

This produces the following output:

     ERROR:root:Problem recorded
     Traceback (most recent call last):
       File "t.py", line 6, in f
         1/0
     ZeroDivisionError: integer division or modulo by zero

Slightly more advanced programs will use a logger other than the root
logger.  The `getLogger(NAME)' function is used to get a particular
log, creating it if it doesn't exist yet.  `getLogger(None)' returns
the root logger.

     log = logging.getLogger('server')
      ...
     log.info('Listening on port %i', port)
      ...
     log.critical('Disk full')
      ...

Log records are usually propagated up the hierarchy, so a message
logged to `server.auth' is also seen by `server' and `root', but a
`Logger' can prevent this by setting its `propagate' attribute to
`False'.

There are more classes provided by the `logging' package that can be
customized.  When a `Logger' instance is told to log a message, it
creates a `LogRecord' instance that is sent to any number of different
`Handler' instances.  Loggers and handlers can also have an attached
list of filters, and each filter can cause the `LogRecord' to be
ignored or can modify the record before passing it along.  When they're
finally output, `LogRecord' instances are converted to text by a
`Formatter' class.  All of these classes can be replaced by your own
specially-written classes.

With all of these features the `logging' package should provide enough
flexibility for even the most complicated applications.  This is only
an incomplete overview of its features, so please see the package's
reference documentation for all of the details.  Reading PEP 282 will
also be helpful.

See also:
    *PEP282 A Logging System*
          Written by Vinay Sajip and Trent Mick; implemented by Vinay
          Sajip.



File: python-whatsnew23.info,  Node: PEP 285 A Boolean Type,  Next: PEP 293 Codec Error Handling Callbacks,  Prev: PEP 282 logging Package,  Up: Top

PEP 285: A Boolean Type
***********************

A Boolean type was added to Python 2.3.  Two new constants were added
to the `__builtin__' module, `True' and `False'.  (`True' and `False'
constants were added to the built-ins in Python 2.2.1, but the 2.2.1
versions are simply set to integer values of 1 and 0 and aren't a
different type.)

The type object for this new type is named `bool'; the constructor for
it takes any Python value and converts it to `True' or `False'.

     >>> bool(1)
     True
     >>> bool(0)
     False
     >>> bool([])
     False
     >>> bool( (1,) )
     True

Most of the standard library modules and built-in functions have been
changed to return Booleans.

     >>> obj = []
     >>> hasattr(obj, 'append')
     True
     >>> isinstance(obj, list)
     True
     >>> isinstance(obj, tuple)
     False

Python's Booleans were added with the primary goal of making code
clearer.  For example, if you're reading a function and encounter the
statement `return 1', you might wonder whether the `1' represents a
Boolean truth value, an index, or a coefficient that multiplies some
other quantity.  If the statement is `return True', however, the
meaning of the return value is quite clear.

Python's Booleans were _not_ added for the sake of strict
type-checking.  A very strict language such as Pascal would also
prevent you performing arithmetic with Booleans, and would require that
the expression in an `if' statement always evaluate to a Boolean
result.  Python is not this strict and never will be, as PEP 285
explicitly says.  This means you can still use any expression in an
`if' statement, even ones that evaluate to a list or tuple or some
random object.  The Boolean type is a subclass of the `int' class so
that arithmetic using a Boolean still works.

     >>> True + 1
     2
     >>> False + 1
     1
     >>> False * 75
     0
     >>> True * 75
     75

To sum up `True' and `False' in a sentence: they're alternative ways to
spell the integer values 1 and 0, with the single difference that
`str()' and `repr()' return the strings `'True'' and `'False'' instead
of `'1'' and `'0''.

See also:
    *PEP285 Adding a bool type*
          Written and implemented by GvR.



File: python-whatsnew23.info,  Node: PEP 293 Codec Error Handling Callbacks,  Next: PEP 301 Package Index and Metadata for Distutils,  Prev: PEP 285 A Boolean Type,  Up: Top

PEP 293: Codec Error Handling Callbacks
***************************************

When encoding a Unicode string into a byte string, unencodable
characters may be encountered.  So far, Python has allowed specifying
the error processing as either "strict" (raising `UnicodeError'),
"ignore" (skipping the character), or "replace" (using a question mark
in the output string), with "strict" being the default behavior. It may
be desirable to specify alternative processing of such errors, such as
inserting an XML character reference or HTML entity reference into the
converted string.

Python now has a flexible framework to add different processing
strategies.  New error handlers can be added with
`codecs.register_error', and codecs then can access the error handler
with `codecs.lookup_error'. An equivalent C API has been added for
codecs written in C. The error handler gets the necessary state
information such as the string being converted, the position in the
string where the error was detected, and the target encoding.  The
handler can then either raise an exception or return a replacement
string.

Two additional error handlers have been implemented using this
framework: "backslashreplace" uses Python backslash quoting to
represent unencodable characters and "xmlcharrefreplace" emits XML
character references.

See also:
    *PEP293 Codec Error Handling Callbacks*
          Written and implemented by Walter D"orwald.



File: python-whatsnew23.info,  Node: PEP 301 Package Index and Metadata for Distutils,  Next: PEP 302 New Import Hooks,  Prev: PEP 293 Codec Error Handling Callbacks,  Up: Top

PEP 301: Package Index and Metadata for Distutils
*************************************************

Support for the long-requested Python catalog makes its first
appearance in 2.3.

The heart of the catalog is the new Distutils `register' command.
Running `python setup.py register' will collect the metadata describing
a package, such as its name, version, maintainer, description, &c., and
send it to a central catalog server.  The resulting catalog is
available from <http://www.python.org/pypi>.

To make the catalog a bit more useful, a new optional CLASSIFIERS
keyword argument has been added to the Distutils `setup()' function.  A
list of Trove-style strings can be supplied to help classify the
software.

Here's an example `setup.py' with classifiers, written to be compatible
with older versions of the Distutils:

     from distutils import core
     kw = {'name': "Quixote",
           'version': "0.5.1",
           'description': "A highly Pythonic Web application framework",
           # ...
           }
     
     if (hasattr(core, 'setup_keywords') and
         'classifiers' in core.setup_keywords):
         kw['classifiers'] = \
             ['Topic :: Internet :: WWW/HTTP :: Dynamic Content',
              'Environment :: No Input/Output (Daemon)',
              'Intended Audience :: Developers'],
     
     core.setup(**kw)

The full list of classifiers can be obtained by running `python
setup.py register --list-classifiers'.

See also:
    *PEP301 Package Index and Metadata for Distutils*
          Written and implemented by Richard Jones.



File: python-whatsnew23.info,  Node: PEP 302 New Import Hooks,  Next: PEP 305 Comma-separated Files,  Prev: PEP 301 Package Index and Metadata for Distutils,  Up: Top

PEP 302: New Import Hooks
*************************

While it's been possible to write custom import hooks ever since the
`ihooks' module was introduced in Python 1.3, no one has ever been
really happy with it because writing new import hooks is difficult and
messy.  There have been various proposed alternatives such as the
`imputil' and `iu' modules, but none of them has ever gained much
acceptance, and none of them were easily usable from C code.

PEP 302 borrows ideas from its predecessors, especially from Gordon
McMillan's `iu' module.  Three new items are added to the `sys' module:

   * `sys.path_hooks' is a list of callable objects; most often they'll
     be classes.  Each callable takes a string containing a path and
     either returns an importer object that will handle imports from
     this path or raises an `ImportError' exception if it can't handle
     this path.

   * `sys.path_importer_cache' caches importer objects for each path,
     so `sys.path_hooks' will only need to be traversed once for each
     path.

   * `sys.meta_path' is a list of importer objects that will be
     traversed before `sys.path' is checked.  This list is initially
     empty, but user code can add objects to it.  Additional built-in
     and frozen modules can be imported by an object added to this list.


Importer objects must have a single method, `find_module(FULLNAME,
PATH=None)'.  FULLNAME will be a module or package name, e.g. `string'
or `distutils.core'.  `find_module()' must return a loader object that
has a single method, `load_module(FULLNAME)', that creates and returns
the corresponding module object.

Pseudo-code for Python's new import logic, therefore, looks something
like this (simplified a bit; see PEP 302 for the full details):

     for mp in sys.meta_path:
         loader = mp(fullname)
         if loader is not None:
             <module> = loader.load_module(fullname)
     
     for path in sys.path:
         for hook in sys.path_hooks:
             try:
                 importer = hook(path)
             except ImportError:
                 # ImportError, so try the other path hooks
                 pass
             else:
                 loader = importer.find_module(fullname)
                 <module> = loader.load_module(fullname)
     
     # Not found!
     raise ImportError

See also:
    *PEP302 New Import Hooks*
          Written by Just van~Rossum and Paul Moore. Implemented by
          Just van~Rossum.



File: python-whatsnew23.info,  Node: PEP 305 Comma-separated Files,  Next: PEP 307 Pickle Enhancements,  Prev: PEP 302 New Import Hooks,  Up: Top

PEP 305: Comma-separated Files
******************************

Comma-separated files are a format frequently used for exporting data
from databases and spreadsheets.  Python 2.3 adds a parser for
comma-separated files.

Comma-separated format is deceptively simple at first glance:

     Costs,150,200,3.95

Read a line and call `line.split(',')': what could be simpler?  But
toss in string data that can contain commas, and things get more
complicated:

     "Costs",150,200,3.95,"Includes taxes, shipping, and sundry items"

A big ugly regular expression can parse this, but using the new `csv'
package is much simpler:

     import csv
     
     input = open('datafile', 'rb')
     reader = csv.reader(input)
     for line in reader:
         print line

The `reader' function takes a number of different options.  The field
separator isn't limited to the comma and can be changed to any
character, and so can the quoting and line-ending characters.

Different dialects of comma-separated files can be defined and
registered; currently there are two dialects, both used by Microsoft
Excel.  A separate `csv.writer' class will generate comma-separated
files from a succession of tuples or lists, quoting strings that
contain the delimiter.

See also:
    *PEP305 CSV File API*
          Written and implemented  by Kevin Altis, Dave Cole, Andrew
          McNamara, Skip Montanaro, Cliff Wells.



File: python-whatsnew23.info,  Node: PEP 307 Pickle Enhancements,  Next: Extended Slices,  Prev: PEP 305 Comma-separated Files,  Up: Top

PEP 307: Pickle Enhancements
****************************

The `pickle' and `cPickle' modules received some attention during the
2.3 development cycle.  In 2.2, new-style classes could be pickled
without difficulty, but they weren't pickled very compactly; PEP 307
quotes a trivial example where a new-style class results in a pickled
string three times longer than that for a classic class.

The solution was to invent a new pickle protocol.  The `pickle.dumps()'
function has supported a text-or-binary flag for a long time.  In 2.3,
this flag is redefined from a Boolean to an integer: 0 is the old
text-mode pickle format, 1 is the old binary format, and now 2 is a new
2.3-specific format.  A new constant, `pickle.HIGHEST_PROTOCOL', can be
used to select the fanciest protocol available.

Unpickling is no longer considered a safe operation.  2.2's `pickle'
provided hooks for trying to prevent unsafe classes from being
unpickled (specifically, a `__safe_for_unpickling__' attribute), but
none of this code was ever audited and therefore it's all been ripped
out in 2.3.  You should not unpickle untrusted data in any version of
Python.

To reduce the pickling overhead for new-style classes, a new interface
for customizing pickling was added using three special methods:
`__getstate__', `__setstate__', and `__getnewargs__'.  Consult PEP 307
for the full semantics of these methods.

As a way to compress pickles yet further, it's now possible to use
integer codes instead of long strings to identify pickled classes.  The
Python Software Foundation will maintain a list of standardized codes;
there's also a range of codes for private use.  Currently no codes have
been specified.

See also:
    *PEP307 Extensions to the pickle protocol*
          Written and implemented  by Guido van Rossum and Tim Peters.



File: python-whatsnew23.info,  Node: Extended Slices,  Next: Other Language Changes,  Prev: PEP 307 Pickle Enhancements,  Up: Top

Extended Slices
***************

Ever since Python 1.4, the slicing syntax has supported an optional
third "step" or "stride" argument.  For example, these are all legal
Python syntax: `L[1:10:2]', `L[:-1:1]', `L[::-1]'.  This was added to
Python at the request of the developers of Numerical Python, which uses
the third argument extensively.  However, Python's built-in list,
tuple, and string sequence types have never supported this feature,
raising a `TypeError' if you tried it.  Michael Hudson contributed a
patch to fix this shortcoming.

For example, you can now easily extract the elements of a list that
have even indexes:

     >>> L = range(10)
     >>> L[::2]
     [0, 2, 4, 6, 8]

Negative values also work to make a copy of the same list in reverse
order:

     >>> L[::-1]
     [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]

This also works for tuples, arrays, and strings:

     >>> s='abcd'
     >>> s[::2]
     'ac'
     >>> s[::-1]
     'dcba'

If you have a mutable sequence such as a list or an array you can
assign to or delete an extended slice, but there are some differences
between assignment to extended and regular slices.  Assignment to a
regular slice can be used to change the length of the sequence:

     >>> a = range(3)
     >>> a
     [0, 1, 2]
     >>> a[1:3] = [4, 5, 6]
     >>> a
     [0, 4, 5, 6]

Extended slices aren't this flexible.  When assigning to an extended
slice, the list on the right hand side of the statement must contain
the same number of items as the slice it is replacing:

     >>> a = range(4)
     >>> a
     [0, 1, 2, 3]
     >>> a[::2]
     [0, 2]
     >>> a[::2] = [0, -1]
     >>> a
     [0, 1, -1, 3]
     >>> a[::2] = [0,1,2]
     Traceback (most recent call last):
       File "<stdin>", line 1, in ?
     ValueError: attempt to assign sequence of size 3 to extended slice of size 2

Deletion is more straightforward:

     >>> a = range(4)
     >>> a
     [0, 1, 2, 3]
     >>> a[::2]
     [0, 2]
     >>> del a[::2]
     >>> a
     [1, 3]

One can also now pass slice objects to the `__getitem__' methods of the
built-in sequences:

     >>> range(10).__getitem__(slice(0, 5, 2))
     [0, 2, 4]

Or use slice objects directly in subscripts:

     >>> range(10)[slice(0, 5, 2)]
     [0, 2, 4]

To simplify implementing sequences that support extended slicing, slice
objects now have a method `indices(LENGTH)' which, given the length of
a sequence, returns a `(START, STOP, STEP)' tuple that can be passed
directly to `range()'.  `indices()' handles omitted and out-of-bounds
indices in a manner consistent with regular slices (and this innocuous
phrase hides a welter of confusing details!).  The method is intended
to be used like this:

     class FakeSeq:
         ...
         def calc_item(self, i):
             ...
         def __getitem__(self, item):
             if isinstance(item, slice):
                 indices = item.indices(len(self))
                 return FakeSeq([self.calc_item(i) for i in range(*indices)])
             else:
                 return self.calc_item(i)

From this example you can also see that the built-in `slice' object is
now the type object for the slice type, and is no longer a function.
This is consistent with Python 2.2, where `int', `str', etc., underwent
the same change.


File: python-whatsnew23.info,  Node: Other Language Changes,  Next: New,  Prev: Extended Slices,  Up: Top

Other Language Changes
**********************

Here are all of the changes that Python 2.3 makes to the core Python
language.

   * The `yield' statement is now always a keyword, as described in
     section~*Note PEP 255 Simple Generators:: of this document.

   * A new built-in function `enumerate()' was added, as described in
     section~*Note PEP 282 logging Package:: of this document.

   * Two new constants, `True' and `False' were added along with the
     built-in `bool' type, as described in section~*Note PEP 293 Codec
     Error Handling Callbacks:: of this document.

   * The `int()' type constructor will now return a long integer
     instead of raising an `OverflowError' when a string or
     floating-point number is too large to fit into an integer.  This
     can lead to the paradoxical result that
     `isinstance(int(EXPRESSION), int)' is false, but that seems
     unlikely to cause problems in practice.

   * Built-in types now support the extended slicing syntax, as
     described in section~*Note optparse Module:: of this document.

   * A new built-in function, `sum(ITERABLE, START=0)', adds up the
     numeric items in the iterable object and returns their sum.
     `sum()' only accepts numbers, meaning that you can't use it to
     concatenate a bunch of strings.   (Contributed by Alex Martelli.)

   * `list.insert(POS, VALUE)' used to insert VALUE at the front of the
     list when POS was negative.  The behaviour has now been changed to
     be consistent with slice indexing, so when POS is -1 the value
     will be inserted before the last element, and so forth.

   * `list.index(VALUE)', which searches for VALUE within the list and
     returns its index, now takes optional START and STOP arguments to
     limit the search to only part of the list.

   * Dictionaries have a new method, `pop(KEY[, DEFAULT])', that
     returns the value corresponding to KEY and removes that key/value
     pair from the dictionary.  If the requested key isn't present in
     the dictionary, DEFAULT is returned if it's specified and
     `KeyError' raised if it isn't.

          >>> d = {1:2}
          >>> d
          {1: 2}
          >>> d.pop(4)
          Traceback (most recent call last):
            File "stdin", line 1, in ?
          KeyError: 4
          >>> d.pop(1)
          2
          >>> d.pop(1)
          Traceback (most recent call last):
            File "stdin", line 1, in ?
          KeyError: 'pop(): dictionary is empty'
          >>> d
          {}
          >>>

     There's also a new class method, `dict.fromkeys(ITERABLE, VALUE)',
     that creates a dictionary with keys taken from the supplied
     iterator ITERABLE and all values set to VALUE, defaulting to
     `None'.

     (Patches contributed by Raymond Hettinger.)

     Also, the `dict()' constructor now accepts keyword arguments to
     simplify creating small dictionaries:

          >>> dict(red=1, blue=2, green=3, black=4)
          {'blue': 2, 'black': 4, 'green': 3, 'red': 1}

     (Contributed by Just van~Rossum.)

   * The `assert' statement no longer checks the `__debug__' flag, so
     you can no longer disable assertions by assigning to `__debug__'.
     Running Python with the `-O' switch will still generate code that
     doesn't execute any assertions.

   * Most type objects are now callable, so you can use them to create
     new objects such as functions, classes, and modules.  (This means
     that the `new' module can be deprecated in a future Python
     version, because you can now use the type objects available in the
     `types' module.)  For example, you can create a new module object
     with the following code:

          >>> import types
          >>> m = types.ModuleType('abc','docstring')
          >>> m
          <module 'abc' (built-in)>
          >>> m.__doc__
          'docstring'

   * A new warning, `PendingDeprecationWarning' was added to indicate
     features which are in the process of being deprecated.  The
     warning will _not_ be printed by default.  To check for use of
     features that will be deprecated in the future, supply
     `-Walways::PendingDeprecationWarning::' on the command line or use
     `warnings.filterwarnings()'.

   * The process of deprecating string-based exceptions, as in `raise
     "Error occurred"', has begun.  Raising a string will now trigger
     `PendingDeprecationWarning'.

   * Using `None' as a variable name will now result in a
     `SyntaxWarning' warning.  In a future version of Python, `None'
     may finally become a keyword.

   * The `xreadlines()' method of file objects, introduced in Python
     2.1, is no longer necessary because files now behave as their own
     iterator.  `xreadlines()' was originally introduced as a faster
     way to loop over all the lines in a file, but now you can simply
     write `for line in file_obj'.  File objects also have a new
     read-only `encoding' attribute that gives the encoding used by the
     file; Unicode strings written to the file will be automatically
     converted to bytes using the given encoding.

   * The method resolution order used by new-style classes has changed,
     though you'll only notice the difference if you have a really
     complicated inheritance hierarchy.  Classic classes are unaffected
     by this change.  Python 2.2 originally used a topological sort of a
     class's ancestors, but 2.3 now uses the C3 algorithm as described
     in the paper "A Monotonic Superclass Linearization for Dylan".  To
     understand the motivation for this change, read Michele
     Simionato's article "Python 2.3 Method Resolution Order", or read
     the thread on python-dev starting with the message at
     <http://mail.python.org/pipermail/python-dev/2002-October/029035.html>.
     Samuele Pedroni first pointed out the problem and also implemented
     the fix by coding the C3 algorithm.

   * Python runs multithreaded programs by switching between threads
     after executing N bytecodes.  The default value for N has been
     increased from 10 to 100 bytecodes, speeding up single-threaded
     applications by reducing the switching overhead.  Some
     multithreaded applications may suffer slower response time, but
     that's easily fixed by setting the limit back to a lower number
     using `sys.setcheckinterval(N)'.  The limit can be retrieved with
     the new `sys.getcheckinterval()' function.

   * One minor but far-reaching change is that the names of extension
     types defined by the modules included with Python now contain the
     module and a `.' in front of the type name.  For example, in
     Python 2.2, if you created a socket and printed its `__class__',
     you'd get this output:

          >>> s = socket.socket()
          >>> s.__class__
          <type 'socket'>

     In 2.3, you get this:
          >>> s.__class__
          <type '_socket.socket'>

   * One of the noted incompatibilities between old- and new-style
     classes has been removed: you can now assign to the `__name__' and
     `__bases__' attributes of new-style classes.  There are some
     restrictions on what can be assigned to `__bases__' along the
     lines of those relating to assigning to an instance's `__class__'
     attribute.


* Menu:

* String Changes::
* Optimizations::


File: python-whatsnew23.info,  Node: String Changes,  Next: Optimizations,  Prev: Other Language Changes,  Up: Other Language Changes

String Changes
==============

   * The `in' operator now works differently for strings.  Previously,
     when evaluating `X in Y' where X and Y are strings, X could only
     be a single character.  That's now changed; X can be a string of
     any length, and `X in Y' will return `True' if X is a substring of
     Y.  If X is the empty string, the result is always `True'.

          >>> 'ab' in 'abcd'
          True
          >>> 'ad' in 'abcd'
          False
          >>> '' in 'abcd'
          True

     Note that this doesn't tell you where the substring starts; if you
     need that information, use the `find()' string method.

   * The `strip()', `lstrip()', and `rstrip()' string methods now have
     an optional argument for specifying the characters to strip.  The
     default is still to remove all whitespace characters:

          >>> '   abc '.strip()
          'abc'
          >>> '><><abc<><><>'.strip('<>')
          'abc'
          >>> '><><abc<><><>\n'.strip('<>')
          'abc<><><>\n'
          >>> u'\u4000\u4001abc\u4000'.strip(u'\u4000')
          u'\u4001abc'
          >>>

     (Suggested by Simon Brunning and implemented by Walter D"orwald.)

   * The `startswith()' and `endswith()' string methods now accept
     negative numbers for the START and END parameters.

   * Another new string method is `zfill()', originally a function in
     the `string' module.  `zfill()' pads a numeric string with zeros
     on the left until it's the specified width.  Note that the `%'
     operator is still more flexible and powerful than `zfill()'.

          >>> '45'.zfill(4)
          '0045'
          >>> '12345'.zfill(4)
          '12345'
          >>> 'goofy'.zfill(6)
          '0goofy'

     (Contributed by Walter D"orwald.)

   * A new type object, `basestring', has been added.  Both 8-bit
     strings and Unicode strings inherit from this type, so
     `isinstance(obj, basestring)' will return `True' for either kind
     of string.  It's a completely abstract type, so you can't create
     `basestring' instances.

   * Interned strings are no longer immortal and will now be
     garbage-collected in the usual way when the only reference to them
     is from the internal dictionary of interned strings.  (Implemented
     by Oren Tirosh.)



File: python-whatsnew23.info,  Node: Optimizations,  Prev: String Changes,  Up: Other Language Changes

Optimizations
=============

   * The creation of new-style class instances has been made much
     faster; they're now faster than classic classes!

   * The `sort()' method of list objects has been extensively rewritten
     by Tim Peters, and the implementation is significantly faster.

   * Multiplication of large long integers is now much faster thanks to
     an implementation of Karatsuba multiplication, an algorithm that
     scales better than the O(n*n) required for the grade-school
     multiplication algorithm.  (Original patch by Christopher A. Craig,
     and significantly reworked by Tim Peters.)

   * The `SET_LINENO' opcode is now gone.  This may provide a small
     speed increase, depending on your compiler's idiosyncrasies.  See
     section~*Note Porting to Python 23:: for a longer explanation.
     (Removed by Michael Hudson.)

   * `xrange()' objects now have their own iterator, making `for i in
     xrange(n)' slightly faster than `for i in range(n)'.  (Patch by
     Raymond Hettinger.)

   * A number of small rearrangements have been made in various
     hotspots to improve performance, such as inlining a function or
     removing some code.  (Implemented mostly by GvR, but lots of
     people have contributed single changes.)


The net result of the 2.3 optimizations is that Python 2.3 runs the
pystone benchmark around 25% faster than Python 2.2.

